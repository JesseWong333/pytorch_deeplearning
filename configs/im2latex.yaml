Data:
  dir_images_train: "/media/Data/hzc/datasets/formulas/0326/"
  dir_images_test: "/media/Data/hzc/datasets/formulas/0326/"
  dir_images_val: "/media/Data/hzc/datasets/formulas/0326/"
  path_matching_train: "/media/Data/hzc/datasets/formulas/all_train.txt"
  path_matching_val: "/media/Data/hzc/datasets/formulas/all_test.txt"
  path_matching_test: "/media/Data/hzc/datasets/formulas/all_test.txt"
  path_formulas_train: "/media/Data/hzc/datasets/formulas/latex_left.txt"
  path_formulas_test: "/media/Data/hzc/datasets/formulas/latex_left.txt"
  path_formulas_val: "/media/Data/hzc/datasets/formulas/latex_left.txt"
  max_iter: null
  max_length_formula: 200
  bucket_train: True
  bucket_val: True
  bucket_test: True
  buckets: [
        [240, 100], [320, 80], [400, 80], [400, 100], [480, 80], [480, 100],
        [560, 80], [560, 100], [640, 80], [640, 100], [720, 80], [720, 100],
        [720, 120], [720, 200], [800, 100], [800, 320], [1000, 200],
        [1000, 400], [1200, 200], [1600, 200]
        ]
  output: "output/"

Vocab:
  unk: "_UNK"
  pad: "_PAD"
  end: "_END"
  init: "_INIT"

  path_vocab: "/media/Data/hzc/datasets/formulas/0603/tokens-utf-8.txt"
  min_count_tok: 2

Training:
  lr_method: "Adam"
  n_epochs: 15
  batch_size: 4
  dropout: 1
  metric_val: "perplexity"
  clip: -1
  lr_init: 1e-3
  lr_min: 1e-4
  start_decay: 6
  end_decay: 13
  lr_warm: 1e-4
  end_warm: 2

Model:
  encoder_cnn: "vanilla"
  positional_embeddings: True
  attn_cell_config:
    cell_type: "lstm"
    num_units: 512
    dim_e: 512
    dim_o: 512
    dim_embeddings: 80
  decoding: "beam_search"
  beam_size: 5,
  div_gamma: 1,
  div_prob: 0
  max_length_formula: 150
  emb_dim: 80
  enc_rnn_h: 256
  dec_rnn_h: 512
  clip_grad: True
  max_grad_norm: 20

